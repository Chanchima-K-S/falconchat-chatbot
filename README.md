# ğŸ¦… FalconChat: Multi-Turn Conversational AI with Falcon-7B-Instruct

FalconChat is a real-time, interactive chatbot built using the **Falcon-7B-Instruct** model via **HuggingFace Transformers**. The chatbot enables natural, multi-turn conversations through dynamic prompting and response generation. It leverages **PyTorch**, **transformers pipeline**, and **token-based control** to simulate engaging dialogues between two characters.

## âœ¨ Features

- ğŸ’¬ Multi-turn dialogue simulation  
- âš™ï¸ Real-time response generation with `text-generation` pipeline  
- ğŸ§  Based on **tiiuae/falcon-7b-instruct** model  
- âš¡ Auto device mapping using `torch` for efficient execution  
- ğŸ§© Custom character naming and dialogue tracking  

## ğŸ› ï¸ Tech Stack

- **Model**: [Falcon-7B-Instruct](https://huggingface.co/tiiuae/falcon-7b-instruct)  
- **Libraries**: `transformers`, `torch`  
- **Language**: Python  
- **Tokenizer Control**: EOS & newline token logic for natural stopping  

## ğŸ§° Requirements

- **Python** â‰¥ 3.7  
- **GPU** with â‰¥ 12 GB VRAM recommended (for `bfloat16` precision)

## ğŸš§ Limitations & Future Work
- ğŸš« Heavy memory usage: Falcon-7B-Instruct is a large model, limited support on CPUs or lower-end GPUs.
- ğŸ”„ No saving of conversations or UI interface. Build UI/UX with Streamlit or Gradio frontend.
